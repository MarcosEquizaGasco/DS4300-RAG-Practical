{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingest_redis import *\n",
    "from src.ingest_chroma import *\n",
    "from src.search import *\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataframe to track experiment results\n",
    "cols =  ['database', 'chunk_size', 'overlap', 'clean', 'embedding', 'chunks_processed', 'time_to_process', 'used_memory_mb', 'query_time']\n",
    "results = pd.DataFrame(columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries: 500\n"
     ]
    }
   ],
   "source": [
    "with open('example_queries.txt', 'r') as file:\n",
    "\n",
    "    # Skip lines that don't contain actual queries (headers, empty lines) and extract example queries\n",
    "    queries = [line.strip() for line in file if line.strip() and not line.strip().startswith('#') and not line.strip().startswith('##')]\n",
    "    queries = [q.split('. ', 1)[1] if '. ' in q else q for q in queries]\n",
    "    \n",
    "    # Print total count\n",
    "    print(f\"Total queries: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with chunk size 100 and overlap 0 created in 11.88 seconds\n",
      "Search with chunk size 100 and overlap 0 completed in 8.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/c154mt9s11x5q965j91l06qw0000gn/T/ipykernel_39439/933467114.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with chunk size 100 and overlap 0 created in 12.46 seconds\n",
      "Search with chunk size 100 and overlap 0 completed in 10.61 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 18.46 seconds\n",
      "Search with chunk size 100 and overlap 50 completed in 9.71 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 20.06 seconds\n",
      "Search with chunk size 100 and overlap 50 completed in 10.91 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 8.63 seconds\n",
      "Search with chunk size 300 and overlap 0 completed in 10.68 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 9.0 seconds\n",
      "Search with chunk size 300 and overlap 0 completed in 9.23 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 9.65 seconds\n",
      "Search with chunk size 300 and overlap 50 completed in 10.83 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 8.61 seconds\n",
      "Search with chunk size 300 and overlap 50 completed in 10.65 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 8.97 seconds\n",
      "Search with chunk size 300 and overlap 100 completed in 10.55 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 9.47 seconds\n",
      "Search with chunk size 300 and overlap 100 completed in 10.97 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 9.18 seconds\n",
      "Search with chunk size 500 and overlap 0 completed in 10.5 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 7.95 seconds\n",
      "Search with chunk size 500 and overlap 0 completed in 10.82 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 7.91 seconds\n",
      "Search with chunk size 500 and overlap 50 completed in 10.61 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 8.47 seconds\n",
      "Search with chunk size 500 and overlap 50 completed in 10.69 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 8.04 seconds\n",
      "Search with chunk size 500 and overlap 100 completed in 11.14 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 8.56 seconds\n",
      "Search with chunk size 500 and overlap 100 completed in 10.71 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 7.41 seconds\n",
      "Search with chunk size 1000 and overlap 0 completed in 9.02 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 6.91 seconds\n",
      "Search with chunk size 1000 and overlap 0 completed in 8.61 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 8.24 seconds\n",
      "Search with chunk size 1000 and overlap 50 completed in 9.76 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 8.08 seconds\n",
      "Search with chunk size 1000 and overlap 50 completed in 9.97 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 8.18 seconds\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.75 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 6.46 seconds\n",
      "Search with chunk size 1000 and overlap 100 completed in 10.25 seconds\n"
     ]
    }
   ],
   "source": [
    "# test different chunk/overlap/clean combos for filling redis database\n",
    "embedding_model = 'nomic-embed-text'\n",
    "db = 'redis'\n",
    "\n",
    "# loop through different options\n",
    "for chunk in [100,300,500,1000]:\n",
    "    for overlap in [0, 50, 100]:\n",
    "\n",
    "        if overlap >= chunk:\n",
    "            continue\n",
    "        for clean in [True, False]:\n",
    "\n",
    "            # clear store before starting\n",
    "            clear_redis_store()\n",
    "\n",
    "            # create and fill redis store\n",
    "            start = time.time()\n",
    "            create_hnsw_index()\n",
    "            chunk_count = process_pdfs_redis(\"data/\", chunk_size=chunk, overlap=overlap, clean = clean)\n",
    "            to_fill = time.time() - start\n",
    "            print(f'Index with chunk size {chunk} and overlap {overlap} created in {round(to_fill, 2)} seconds')\n",
    "\n",
    "\n",
    "            # Get memory usage info\n",
    "            memory_info = redis_client.info('memory')\n",
    "            used_memory = memory_info['used_memory'] \n",
    "            used_memory_mb = used_memory / (1024 * 1024)\n",
    "\n",
    "            # test retrieval speed\n",
    "            start = time.time()\n",
    "            for query in queries:\n",
    "                query_redis(query)\n",
    "            to_search = time.time()- start\n",
    "            print(f'Search with chunk size {chunk} and overlap {overlap} completed in {round(to_search, 2)} seconds')\n",
    "\n",
    "            # add results to result dataframe\n",
    "            new_row = [db, chunk, overlap, clean, embedding_model, chunk_count, to_fill, used_memory_mb, to_search]\n",
    "            results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with chunk size 100 and overlap 0 created in 17.22 seconds\n",
      "It uses 1274880 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 8.22 seconds\n",
      "Index with chunk size 100 and overlap 0 created in 14.8 seconds\n",
      "It uses 1299456 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 7.7 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 20.74 seconds\n",
      "It uses 1956864 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 8.38 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 21.66 seconds\n",
      "It uses 2055168 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 6.94 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 12.79 seconds\n",
      "It uses 930816 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 7.68 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 13.11 seconds\n",
      "It uses 936960 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 8.36 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 13.26 seconds\n",
      "It uses 967680 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 8.09 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 12.98 seconds\n",
      "It uses 973824 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 5.89 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 14.37 seconds\n",
      "It uses 1010688 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 8.06 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 16.7 seconds\n",
      "It uses 1019904 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 8.93 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 15.14 seconds\n",
      "It uses 890880 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 9.39 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 13.44 seconds\n",
      "It uses 890880 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 8.21 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 12.62 seconds\n",
      "It uses 897024 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 8.02 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 12.21 seconds\n",
      "It uses 900096 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 7.73 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 13.5 seconds\n",
      "It uses 909312 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 8.56 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 13.96 seconds\n",
      "It uses 909312 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 8.66 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 13.07 seconds\n",
      "It uses 854016 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 8.44 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 13.99 seconds\n",
      "It uses 854016 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 8.92 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 12.29 seconds\n",
      "It uses 854016 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 7.98 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 13.18 seconds\n",
      "It uses 854016 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 7.76 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 12.37 seconds\n",
      "It uses 857088 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.52 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 13.05 seconds\n",
      "It uses 860160 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.33 seconds\n"
     ]
    }
   ],
   "source": [
    "# test different chunk/overlap/clean combos for filling redis database\n",
    "embedding_model = 'nomic-embed-text'\n",
    "embedding_size = 768\n",
    "db = 'chroma'\n",
    "\n",
    "# loop through different options\n",
    "for chunk in [100,300,500,1000]:\n",
    "    for overlap in [0, 50, 100]:\n",
    "        if overlap >= chunk:\n",
    "            continue\n",
    "        for clean in [True, False]:\n",
    "\n",
    "            # create and fill redis store\n",
    "            start = time.time()\n",
    "            collection = create_chroma_index(embedding_model)\n",
    "            collection, chunk_count = process_pdfs_chroma(collection, \"data/\", chunk_size=chunk, overlap=overlap, clean = clean)\n",
    "            to_fill = time.time() - start\n",
    "            print(f'Index with chunk size {chunk} and overlap {overlap} created in {round(to_fill, 2)} seconds')\n",
    "\n",
    "            num_vectors = len(collection.get()[\"ids\"])  # Number of stored items\n",
    "            embedding_size = 768  # Adjust based on your embedding model\n",
    "            float_size = np.dtype(np.float32).itemsize  # 4 bytes per float\n",
    "\n",
    "            memory_usage_bytes = num_vectors * embedding_size * float_size\n",
    "            memory_usage_mb = memory_usage_bytes / (1024 * 1024)\n",
    "            print(f\"It uses {memory_usage_bytes} MB\")\n",
    "\n",
    "            # test searching speed\n",
    "            start = time.time()\n",
    "            query_chroma(collection, queries)\n",
    "            to_search = time.time()-start\n",
    "            print(f'Search with chunk size {chunk} and overlap {overlap} completed in {round(to_search, 2)} seconds')\n",
    "\n",
    "            # add results to result dataframe\n",
    "            new_row = [db, chunk, overlap, clean, embedding_model, chunk_count, to_fill, used_memory_mb, to_search]\n",
    "            results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>overlap</th>\n",
       "      <th>clean</th>\n",
       "      <th>embedding</th>\n",
       "      <th>chunks_processed</th>\n",
       "      <th>time_to_process</th>\n",
       "      <th>used_memory_mb</th>\n",
       "      <th>query_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chroma</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>nomic-embed-text</td>\n",
       "      <td>(Collection(name=hnsw_index), 415)</td>\n",
       "      <td>17.220127</td>\n",
       "      <td>6.475861</td>\n",
       "      <td>8.222336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chroma</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>nomic-embed-text</td>\n",
       "      <td>(Collection(name=hnsw_index), 423)</td>\n",
       "      <td>14.803474</td>\n",
       "      <td>6.475861</td>\n",
       "      <td>7.699875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chroma</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>nomic-embed-text</td>\n",
       "      <td>(Collection(name=hnsw_index), 637)</td>\n",
       "      <td>20.736971</td>\n",
       "      <td>6.475861</td>\n",
       "      <td>8.375115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chroma</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>nomic-embed-text</td>\n",
       "      <td>(Collection(name=hnsw_index), 669)</td>\n",
       "      <td>21.660947</td>\n",
       "      <td>6.475861</td>\n",
       "      <td>6.938353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chroma</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>nomic-embed-text</td>\n",
       "      <td>(Collection(name=hnsw_index), 303)</td>\n",
       "      <td>12.789091</td>\n",
       "      <td>6.475861</td>\n",
       "      <td>7.682276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  database chunk_size overlap  clean         embedding  \\\n",
       "0   chroma        100       0   True  nomic-embed-text   \n",
       "0   chroma        100       0  False  nomic-embed-text   \n",
       "0   chroma        100      50   True  nomic-embed-text   \n",
       "0   chroma        100      50  False  nomic-embed-text   \n",
       "0   chroma        300       0   True  nomic-embed-text   \n",
       "\n",
       "                     chunks_processed  time_to_process  used_memory_mb  \\\n",
       "0  (Collection(name=hnsw_index), 415)        17.220127        6.475861   \n",
       "0  (Collection(name=hnsw_index), 423)        14.803474        6.475861   \n",
       "0  (Collection(name=hnsw_index), 637)        20.736971        6.475861   \n",
       "0  (Collection(name=hnsw_index), 669)        21.660947        6.475861   \n",
       "0  (Collection(name=hnsw_index), 303)        12.789091        6.475861   \n",
       "\n",
       "   query_time  \n",
       "0    8.222336  \n",
       "0    7.699875  \n",
       "0    8.375115  \n",
       "0    6.938353  \n",
       "0    7.682276  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['database']=='chroma'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.reset_index().loc[35, 'chunks_processed'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('experiment_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac_2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
