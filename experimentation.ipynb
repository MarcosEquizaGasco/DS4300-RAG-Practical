{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingest_redis import *\n",
    "from src.ingest_chroma import *\n",
    "from src.ingest_milvus import * \n",
    "from src.search import *\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from pymilvus import connections, utility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataframe to track experiment results\n",
    "cols =  ['database', 'chunk_size', 'overlap', 'clean', 'embedding', 'chunks_processed', 'time_to_process', 'used_memory_mb', 'query_time']\n",
    "results = pd.DataFrame(columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries: 500\n"
     ]
    }
   ],
   "source": [
    "with open('example_queries.txt', 'r') as file:\n",
    "\n",
    "    # Skip lines that don't contain actual queries (headers, empty lines) and extract example queries\n",
    "    queries = [line.strip() for line in file if line.strip() and not line.strip().startswith('#') and not line.strip().startswith('##')]\n",
    "    queries = [q.split('. ', 1)[1] if '. ' in q else q for q in queries]\n",
    "    \n",
    "    # Print total count\n",
    "    print(f\"Total queries: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with chunk size 100 and overlap 0 created in 10.43 seconds\n",
      "Search with chunk size 100 and overlap 0 completed in 9.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/c154mt9s11x5q965j91l06qw0000gn/T/ipykernel_7749/121440660.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with chunk size 100 and overlap 0 created in 10.19 seconds\n",
      "Search with chunk size 100 and overlap 0 completed in 9.45 seconds\n",
      "Index with chunk size 100 and overlap 0 created in 11.47 seconds\n",
      "Search with chunk size 100 and overlap 0 completed in 11.94 seconds\n",
      "Index with chunk size 100 and overlap 0 created in 15.37 seconds\n",
      "Search with chunk size 100 and overlap 0 completed in 11.93 seconds\n",
      "Index with chunk size 100 and overlap 0 created in 15.41 seconds\n",
      "Search with chunk size 100 and overlap 0 completed in 11.49 seconds\n",
      "Index with chunk size 100 and overlap 0 created in 15.34 seconds\n",
      "Search with chunk size 100 and overlap 0 completed in 10.43 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 21.64 seconds\n",
      "Search with chunk size 100 and overlap 50 completed in 12.12 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 25.04 seconds\n",
      "Search with chunk size 100 and overlap 50 completed in 12.15 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 23.0 seconds\n",
      "Search with chunk size 100 and overlap 50 completed in 11.9 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 24.02 seconds\n",
      "Search with chunk size 100 and overlap 50 completed in 10.92 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 22.97 seconds\n",
      "Search with chunk size 100 and overlap 50 completed in 10.98 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 24.92 seconds\n",
      "Search with chunk size 100 and overlap 50 completed in 11.43 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 10.01 seconds\n",
      "Search with chunk size 300 and overlap 0 completed in 11.95 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 9.99 seconds\n",
      "Search with chunk size 300 and overlap 0 completed in 10.92 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 10.89 seconds\n",
      "Search with chunk size 300 and overlap 0 completed in 10.97 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 12.24 seconds\n",
      "Search with chunk size 300 and overlap 0 completed in 10.59 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 12.41 seconds\n",
      "Search with chunk size 300 and overlap 0 completed in 10.71 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 12.58 seconds\n",
      "Search with chunk size 300 and overlap 0 completed in 10.03 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 9.52 seconds\n",
      "Search with chunk size 300 and overlap 50 completed in 10.56 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 9.43 seconds\n",
      "Search with chunk size 300 and overlap 50 completed in 10.72 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 11.89 seconds\n",
      "Search with chunk size 300 and overlap 50 completed in 10.01 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 12.5 seconds\n",
      "Search with chunk size 300 and overlap 50 completed in 10.31 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 12.27 seconds\n",
      "Search with chunk size 300 and overlap 50 completed in 10.34 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 12.69 seconds\n",
      "Search with chunk size 300 and overlap 50 completed in 9.97 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 9.71 seconds\n",
      "Search with chunk size 300 and overlap 100 completed in 10.74 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 10.33 seconds\n",
      "Search with chunk size 300 and overlap 100 completed in 10.66 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 12.6 seconds\n",
      "Search with chunk size 300 and overlap 100 completed in 9.66 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 12.35 seconds\n",
      "Search with chunk size 300 and overlap 100 completed in 9.4 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 12.55 seconds\n",
      "Search with chunk size 300 and overlap 100 completed in 10.4 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 13.44 seconds\n",
      "Search with chunk size 300 and overlap 100 completed in 9.83 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 9.1 seconds\n",
      "Search with chunk size 500 and overlap 0 completed in 11.33 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 9.45 seconds\n",
      "Search with chunk size 500 and overlap 0 completed in 11.24 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 10.92 seconds\n",
      "Search with chunk size 500 and overlap 0 completed in 10.61 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 11.77 seconds\n",
      "Search with chunk size 500 and overlap 0 completed in 10.64 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 10.69 seconds\n",
      "Search with chunk size 500 and overlap 0 completed in 9.77 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 11.96 seconds\n",
      "Search with chunk size 500 and overlap 0 completed in 10.91 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 9.41 seconds\n",
      "Search with chunk size 500 and overlap 50 completed in 11.33 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 9.35 seconds\n",
      "Search with chunk size 500 and overlap 50 completed in 11.44 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 11.54 seconds\n",
      "Search with chunk size 500 and overlap 50 completed in 11.06 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 11.49 seconds\n",
      "Search with chunk size 500 and overlap 50 completed in 10.91 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 11.77 seconds\n",
      "Search with chunk size 500 and overlap 50 completed in 9.85 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 10.93 seconds\n",
      "Search with chunk size 500 and overlap 50 completed in 9.26 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 9.35 seconds\n",
      "Search with chunk size 500 and overlap 100 completed in 11.49 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 9.42 seconds\n",
      "Search with chunk size 500 and overlap 100 completed in 10.44 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 10.75 seconds\n",
      "Search with chunk size 500 and overlap 100 completed in 10.48 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 12.03 seconds\n",
      "Search with chunk size 500 and overlap 100 completed in 10.23 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 11.7 seconds\n",
      "Search with chunk size 500 and overlap 100 completed in 9.12 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 10.2 seconds\n",
      "Search with chunk size 500 and overlap 100 completed in 9.72 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 9.01 seconds\n",
      "Search with chunk size 1000 and overlap 0 completed in 11.54 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 9.39 seconds\n",
      "Search with chunk size 1000 and overlap 0 completed in 11.55 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 10.71 seconds\n",
      "Search with chunk size 1000 and overlap 0 completed in 9.83 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 8.88 seconds\n",
      "Search with chunk size 1000 and overlap 0 completed in 8.21 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 9.89 seconds\n",
      "Search with chunk size 1000 and overlap 0 completed in 9.65 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 10.98 seconds\n",
      "Search with chunk size 1000 and overlap 0 completed in 11.32 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 9.16 seconds\n",
      "Search with chunk size 1000 and overlap 50 completed in 11.47 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 9.49 seconds\n",
      "Search with chunk size 1000 and overlap 50 completed in 10.11 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 8.75 seconds\n",
      "Search with chunk size 1000 and overlap 50 completed in 9.01 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 10.44 seconds\n",
      "Search with chunk size 1000 and overlap 50 completed in 10.15 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 11.5 seconds\n",
      "Search with chunk size 1000 and overlap 50 completed in 8.42 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 9.79 seconds\n",
      "Search with chunk size 1000 and overlap 50 completed in 8.31 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 6.87 seconds\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.91 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 7.82 seconds\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.69 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 8.26 seconds\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.1 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 8.15 seconds\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.94 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 9.3 seconds\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.1 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 9.49 seconds\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.04 seconds\n"
     ]
    }
   ],
   "source": [
    "# test different chunk/overlap/clean combos for filling redis database\n",
    "embedding_models = {'nomic-embed-text':768, 'mxbai-embed-large':512, 'bge-m3':1024}\n",
    "db = 'redis'\n",
    "\n",
    "# loop through different options\n",
    "for chunk in [100,300,500,1000]:\n",
    "    for overlap in [0, 50, 100]:\n",
    "        for embedding_model, embed_size in embedding_models.items():\n",
    "\n",
    "            if overlap >= chunk:\n",
    "                continue\n",
    "            \n",
    "            for clean in [True, False]:\n",
    "\n",
    "                # clear store before starting\n",
    "                clear_redis_store()\n",
    "\n",
    "                # create and fill redis store\n",
    "                start = time.time()\n",
    "                create_hnsw_index()\n",
    "                chunk_count = process_pdfs_redis(\"data/\", chunk_size=chunk, overlap=overlap, clean = clean, model=embedding_model)\n",
    "                to_fill = time.time() - start\n",
    "                print(f'Index with chunk size {chunk} and overlap {overlap} created in {round(to_fill, 2)} seconds')\n",
    "\n",
    "\n",
    "                # Get memory usage info\n",
    "                memory_info = redis_client.info('memory')\n",
    "                used_memory = memory_info['used_memory'] \n",
    "                used_memory_mb = used_memory / (1024 * 1024)\n",
    "\n",
    "                # test retrieval speed\n",
    "                start = time.time()\n",
    "                for query in queries:\n",
    "                    query_redis(query)\n",
    "                to_search = time.time()- start\n",
    "                print(f'Search with chunk size {chunk} and overlap {overlap} completed in {round(to_search, 2)} seconds')\n",
    "\n",
    "                # add results to result dataframe\n",
    "                new_row = [db, chunk, overlap, clean, embedding_model, chunk_count, to_fill, used_memory_mb, to_search]\n",
    "                results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with chunk size 100 and overlap 0 created in 16.76 seconds\n",
      "It uses 1274880 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 7.62 seconds\n",
      "Index with chunk size 100 and overlap 0 created in 14.78 seconds\n",
      "It uses 1299456 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 6.63 seconds\n",
      "Index with chunk size 100 and overlap 0 created in 18.42 seconds\n",
      "It uses 849920 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 7.7 seconds\n",
      "Index with chunk size 100 and overlap 0 created in 18.42 seconds\n",
      "It uses 866304 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 7.78 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 19.52 seconds\n",
      "It uses 1956864 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 7.13 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 21.87 seconds\n",
      "It uses 2055168 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 7.54 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 26.42 seconds\n",
      "It uses 1304576 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 9.59 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 29.0 seconds\n",
      "It uses 1370112 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 9.91 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 14.49 seconds\n",
      "It uses 930816 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 8.42 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 14.85 seconds\n",
      "It uses 936960 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 8.46 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 17.92 seconds\n",
      "It uses 620544 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 9.86 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 18.64 seconds\n",
      "It uses 624640 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 9.71 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 12.93 seconds\n",
      "It uses 967680 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 6.57 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 13.19 seconds\n",
      "It uses 973824 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 6.92 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 18.34 seconds\n",
      "It uses 645120 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 10.48 seconds\n",
      "Index with chunk size 300 and overlap 50 created in 20.01 seconds\n",
      "It uses 649216 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 10.05 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 15.93 seconds\n",
      "It uses 1010688 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 8.99 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 16.26 seconds\n",
      "It uses 1019904 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 7.58 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 17.81 seconds\n",
      "It uses 673792 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 10.32 seconds\n",
      "Index with chunk size 300 and overlap 100 created in 19.27 seconds\n",
      "It uses 679936 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 7.55 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 11.78 seconds\n",
      "It uses 890880 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 7.2 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 12.53 seconds\n",
      "It uses 890880 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 7.66 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 16.46 seconds\n",
      "It uses 593920 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 9.73 seconds\n",
      "Index with chunk size 500 and overlap 0 created in 17.72 seconds\n",
      "It uses 593920 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 10.17 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 13.44 seconds\n",
      "It uses 897024 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 7.4 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 11.39 seconds\n",
      "It uses 900096 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 5.86 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 15.38 seconds\n",
      "It uses 598016 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 7.86 seconds\n",
      "Index with chunk size 500 and overlap 50 created in 15.79 seconds\n",
      "It uses 600064 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 7.67 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 11.91 seconds\n",
      "It uses 909312 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 7.76 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 12.08 seconds\n",
      "It uses 909312 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 7.1 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 17.31 seconds\n",
      "It uses 606208 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 10.3 seconds\n",
      "Index with chunk size 500 and overlap 100 created in 16.25 seconds\n",
      "It uses 606208 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 8.82 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 12.34 seconds\n",
      "It uses 854016 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 7.15 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 12.79 seconds\n",
      "It uses 854016 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 6.63 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 15.1 seconds\n",
      "It uses 569344 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 8.71 seconds\n",
      "Index with chunk size 1000 and overlap 0 created in 16.07 seconds\n",
      "It uses 569344 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 7.74 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 12.6 seconds\n",
      "It uses 854016 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 8.81 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 13.72 seconds\n",
      "It uses 854016 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 8.61 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 15.45 seconds\n",
      "It uses 569344 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 7.52 seconds\n",
      "Index with chunk size 1000 and overlap 50 created in 15.17 seconds\n",
      "It uses 569344 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 7.79 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 12.16 seconds\n",
      "It uses 857088 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 7.1 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 12.71 seconds\n",
      "It uses 860160 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 6.93 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 15.21 seconds\n",
      "It uses 571392 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.03 seconds\n",
      "Index with chunk size 1000 and overlap 100 created in 16.12 seconds\n",
      "It uses 573440 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 8.64 seconds\n"
     ]
    }
   ],
   "source": [
    "db = 'chroma'\n",
    "\n",
    "# loop through different options\n",
    "for chunk in [100,300,500,1000]:\n",
    "    for overlap in [0, 50, 100]:\n",
    "        for embedding_model, embed_size in embedding_models.items():\n",
    "\n",
    "            if embedding_model == 'bge-m3':\n",
    "                continue\n",
    "\n",
    "            if overlap >= chunk:\n",
    "                continue\n",
    "            for clean in [True, False]:\n",
    "\n",
    "                # create and fill redis store\n",
    "                start = time.time()\n",
    "                collection = create_chroma_index(embedding_model)\n",
    "                collection, chunk_count = process_pdfs_chroma(collection, \"data/\", chunk_size=chunk, overlap=overlap, clean = clean)\n",
    "                to_fill = time.time() - start\n",
    "                print(f'Index with chunk size {chunk} and overlap {overlap} created in {round(to_fill, 2)} seconds')\n",
    "\n",
    "                num_vectors = len(collection.get()[\"ids\"])  # Number of stored items\n",
    "                embedding_size = embed_size\n",
    "                float_size = np.dtype(np.float32).itemsize  # 4 bytes per float\n",
    "\n",
    "                memory_usage_bytes = num_vectors * embedding_size * float_size\n",
    "                memory_usage_mb = memory_usage_bytes / (1024 * 1024)\n",
    "                print(f\"It uses {memory_usage_bytes} MB\")\n",
    "\n",
    "                # test searching speed\n",
    "                start = time.time()\n",
    "                query_chroma(collection, queries)\n",
    "                to_search = time.time()-start\n",
    "                print(f'Search with chunk size {chunk} and overlap {overlap} completed in {round(to_search, 2)} seconds')\n",
    "\n",
    "                # add results to result dataframe\n",
    "                new_row = [db, chunk, overlap, clean, embedding_model, chunk_count, to_fill, memory_usage_mb, to_search]\n",
    "                results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection with chunk size 100 and overlap 0 created in 11.79 seconds\n",
      "It uses 1.2158203125 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 14.77 seconds\n",
      "Collection with chunk size 100 and overlap 0 created in 11.83 seconds\n",
      "It uses 1.2392578125 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 16.33 seconds\n",
      "Collection with chunk size 100 and overlap 0 created in 11.54 seconds\n",
      "It uses 0.810546875 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 15.96 seconds\n",
      "Collection with chunk size 100 and overlap 0 created in 12.0 seconds\n",
      "It uses 0.826171875 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 15.19 seconds\n",
      "Collection with chunk size 100 and overlap 0 created in 11.86 seconds\n",
      "It uses 1.62109375 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 14.15 seconds\n",
      "Collection with chunk size 100 and overlap 0 created in 11.77 seconds\n",
      "It uses 1.65234375 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 15.31 seconds\n",
      "Collection with chunk size 100 and overlap 50 created in 13.7 seconds\n",
      "It uses 1.8662109375 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 14.81 seconds\n",
      "Collection with chunk size 100 and overlap 50 created in 15.16 seconds\n",
      "It uses 1.9599609375 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 15.68 seconds\n",
      "Collection with chunk size 100 and overlap 50 created in 14.46 seconds\n",
      "It uses 1.244140625 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 14.58 seconds\n",
      "Collection with chunk size 100 and overlap 50 created in 15.69 seconds\n",
      "It uses 1.306640625 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 15.32 seconds\n",
      "Collection with chunk size 100 and overlap 50 created in 14.33 seconds\n",
      "It uses 2.48828125 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 14.01 seconds\n",
      "Collection with chunk size 100 and overlap 50 created in 15.05 seconds\n",
      "It uses 2.61328125 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 14.72 seconds\n",
      "Collection with chunk size 300 and overlap 0 created in 9.25 seconds\n",
      "It uses 0.8876953125 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 15.04 seconds\n",
      "Collection with chunk size 300 and overlap 0 created in 9.85 seconds\n",
      "It uses 0.8935546875 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 14.54 seconds\n",
      "Collection with chunk size 300 and overlap 0 created in 8.99 seconds\n",
      "It uses 0.591796875 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 14.62 seconds\n",
      "Collection with chunk size 300 and overlap 0 created in 10.34 seconds\n",
      "It uses 0.595703125 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 14.14 seconds\n",
      "Collection with chunk size 300 and overlap 0 created in 9.41 seconds\n",
      "It uses 1.18359375 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 14.33 seconds\n",
      "Collection with chunk size 300 and overlap 0 created in 9.7 seconds\n",
      "It uses 1.19140625 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 15.09 seconds\n",
      "Collection with chunk size 300 and overlap 50 created in 9.77 seconds\n",
      "It uses 0.9228515625 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 15.25 seconds\n",
      "Collection with chunk size 300 and overlap 50 created in 9.77 seconds\n",
      "It uses 0.9287109375 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 15.25 seconds\n",
      "Collection with chunk size 300 and overlap 50 created in 9.82 seconds\n",
      "It uses 0.615234375 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 14.74 seconds\n",
      "Collection with chunk size 300 and overlap 50 created in 9.27 seconds\n",
      "It uses 0.619140625 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 14.12 seconds\n",
      "Collection with chunk size 300 and overlap 50 created in 8.79 seconds\n",
      "It uses 1.23046875 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 14.86 seconds\n",
      "Collection with chunk size 300 and overlap 50 created in 9.13 seconds\n",
      "It uses 1.23828125 MB\n",
      "Search with chunk size 300 and overlap 50 completed in 14.16 seconds\n",
      "Collection with chunk size 300 and overlap 100 created in 8.82 seconds\n",
      "It uses 0.9638671875 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 15.18 seconds\n",
      "Collection with chunk size 300 and overlap 100 created in 9.86 seconds\n",
      "It uses 0.97265625 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 14.53 seconds\n",
      "Collection with chunk size 300 and overlap 100 created in 9.51 seconds\n",
      "It uses 0.642578125 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 14.03 seconds\n",
      "Collection with chunk size 300 and overlap 100 created in 10.0 seconds\n",
      "It uses 0.6484375 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 14.27 seconds\n",
      "Collection with chunk size 300 and overlap 100 created in 9.68 seconds\n",
      "It uses 1.28515625 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 14.12 seconds\n",
      "Collection with chunk size 300 and overlap 100 created in 10.26 seconds\n",
      "It uses 1.296875 MB\n",
      "Search with chunk size 300 and overlap 100 completed in 15.11 seconds\n",
      "Collection with chunk size 500 and overlap 0 created in 9.85 seconds\n",
      "It uses 0.849609375 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 15.71 seconds\n",
      "Collection with chunk size 500 and overlap 0 created in 9.98 seconds\n",
      "It uses 0.849609375 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 14.63 seconds\n",
      "Collection with chunk size 500 and overlap 0 created in 9.32 seconds\n",
      "It uses 0.56640625 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 15.72 seconds\n",
      "Collection with chunk size 500 and overlap 0 created in 9.26 seconds\n",
      "It uses 0.56640625 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 15.32 seconds\n",
      "Collection with chunk size 500 and overlap 0 created in 9.59 seconds\n",
      "It uses 1.1328125 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 15.67 seconds\n",
      "Collection with chunk size 500 and overlap 0 created in 10.4 seconds\n",
      "It uses 1.1328125 MB\n",
      "Search with chunk size 500 and overlap 0 completed in 15.65 seconds\n",
      "Collection with chunk size 500 and overlap 50 created in 9.47 seconds\n",
      "It uses 0.85546875 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 15.39 seconds\n",
      "Collection with chunk size 500 and overlap 50 created in 10.85 seconds\n",
      "It uses 0.8583984375 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 16.03 seconds\n",
      "Collection with chunk size 500 and overlap 50 created in 9.66 seconds\n",
      "It uses 0.5703125 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 15.47 seconds\n",
      "Collection with chunk size 500 and overlap 50 created in 9.54 seconds\n",
      "It uses 0.572265625 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 15.21 seconds\n",
      "Collection with chunk size 500 and overlap 50 created in 9.77 seconds\n",
      "It uses 1.140625 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 15.35 seconds\n",
      "Collection with chunk size 500 and overlap 50 created in 9.57 seconds\n",
      "It uses 1.14453125 MB\n",
      "Search with chunk size 500 and overlap 50 completed in 15.33 seconds\n",
      "Collection with chunk size 500 and overlap 100 created in 9.72 seconds\n",
      "It uses 0.8671875 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 15.45 seconds\n",
      "Collection with chunk size 500 and overlap 100 created in 9.56 seconds\n",
      "It uses 0.8671875 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 15.18 seconds\n",
      "Collection with chunk size 500 and overlap 100 created in 9.75 seconds\n",
      "It uses 0.578125 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 15.57 seconds\n",
      "Collection with chunk size 500 and overlap 100 created in 10.47 seconds\n",
      "It uses 0.578125 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 14.92 seconds\n",
      "Collection with chunk size 500 and overlap 100 created in 10.2 seconds\n",
      "It uses 1.15625 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 15.02 seconds\n",
      "Collection with chunk size 500 and overlap 100 created in 9.88 seconds\n",
      "It uses 1.15625 MB\n",
      "Search with chunk size 500 and overlap 100 completed in 14.84 seconds\n",
      "Collection with chunk size 1000 and overlap 0 created in 9.17 seconds\n",
      "It uses 0.814453125 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 14.67 seconds\n",
      "Collection with chunk size 1000 and overlap 0 created in 9.42 seconds\n",
      "It uses 0.814453125 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 15.82 seconds\n",
      "Collection with chunk size 1000 and overlap 0 created in 10.06 seconds\n",
      "It uses 0.54296875 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 14.6 seconds\n",
      "Collection with chunk size 1000 and overlap 0 created in 9.47 seconds\n",
      "It uses 0.54296875 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 15.02 seconds\n",
      "Collection with chunk size 1000 and overlap 0 created in 10.3 seconds\n",
      "It uses 1.0859375 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 15.74 seconds\n",
      "Collection with chunk size 1000 and overlap 0 created in 9.82 seconds\n",
      "It uses 1.0859375 MB\n",
      "Search with chunk size 1000 and overlap 0 completed in 15.07 seconds\n",
      "Collection with chunk size 1000 and overlap 50 created in 9.9 seconds\n",
      "It uses 0.814453125 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 14.97 seconds\n",
      "Collection with chunk size 1000 and overlap 50 created in 10.02 seconds\n",
      "It uses 0.814453125 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 15.08 seconds\n",
      "Collection with chunk size 1000 and overlap 50 created in 9.96 seconds\n",
      "It uses 0.54296875 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 15.04 seconds\n",
      "Collection with chunk size 1000 and overlap 50 created in 10.04 seconds\n",
      "It uses 0.54296875 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 15.67 seconds\n",
      "Collection with chunk size 1000 and overlap 50 created in 9.37 seconds\n",
      "It uses 1.0859375 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 14.6 seconds\n",
      "Collection with chunk size 1000 and overlap 50 created in 9.31 seconds\n",
      "It uses 1.0859375 MB\n",
      "Search with chunk size 1000 and overlap 50 completed in 15.28 seconds\n",
      "Collection with chunk size 1000 and overlap 100 created in 9.68 seconds\n",
      "It uses 0.8173828125 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 15.56 seconds\n",
      "Collection with chunk size 1000 and overlap 100 created in 9.48 seconds\n",
      "It uses 0.8203125 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 15.07 seconds\n",
      "Collection with chunk size 1000 and overlap 100 created in 8.81 seconds\n",
      "It uses 0.544921875 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 15.23 seconds\n",
      "Collection with chunk size 1000 and overlap 100 created in 9.88 seconds\n",
      "It uses 0.546875 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 15.52 seconds\n",
      "Collection with chunk size 1000 and overlap 100 created in 9.52 seconds\n",
      "It uses 1.08984375 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 15.48 seconds\n",
      "Collection with chunk size 1000 and overlap 100 created in 9.43 seconds\n",
      "It uses 1.09375 MB\n",
      "Search with chunk size 1000 and overlap 100 completed in 15.12 seconds\n"
     ]
    }
   ],
   "source": [
    "db = 'milvus'\n",
    "\n",
    "# loop through different options\n",
    "for chunk in [100,300,500,1000]:\n",
    "    for overlap in [0, 50, 100]:\n",
    "        for embedding_model, embed_size in embedding_models.items():\n",
    "\n",
    "            if overlap >= chunk:\n",
    "                continue\n",
    "            for clean in [True, False]:\n",
    "\n",
    "                # create and fill redis store\n",
    "                start = time.time()\n",
    "                collection = create_milvus_collection(embed_model = embedding_model)\n",
    "                collection, chunk_count = process_pdfs_milvus(collection, \"data/\", chunk_size=chunk, overlap=overlap, clean = clean)\n",
    "                to_fill = time.time() - start\n",
    "                print(f'Collection with chunk size {chunk} and overlap {overlap} created in {round(to_fill, 2)} seconds')\n",
    "\n",
    "                # Get number of stored vectors\n",
    "                num_vectors = collection.num_entities  # Total stored items\n",
    "                embedding_size = embed_size\n",
    "                float_size = np.dtype(np.float32).itemsize  # 4 bytes per float\n",
    "\n",
    "                memory_usage_bytes = num_vectors * embedding_size * float_size\n",
    "                memory_usage_mb = memory_usage_bytes / (1024 * 1024)\n",
    "                \n",
    "                # # Convert to MB\n",
    "                # total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "                print(f\"It uses {memory_usage_mb} MB\")\n",
    "\n",
    "                # test searching speed\n",
    "                start = time.time()\n",
    "                for query in queries:\n",
    "                    query_milvus(collection, query)\n",
    "                to_search = time.time()-start\n",
    "                print(f'Search with chunk size {chunk} and overlap {overlap} completed in {round(to_search, 2)} seconds')\n",
    "\n",
    "                # add results to result dataframe\n",
    "                new_row = [db, chunk, overlap, clean, embedding_model, chunk_count, to_fill, used_memory_mb, to_search]\n",
    "                results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac_2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
