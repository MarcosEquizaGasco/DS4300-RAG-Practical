{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingest_redis import *\n",
    "from src.ingest_chroma import *\n",
    "from src.ingest_milvus import * \n",
    "from src.search import *\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataframe to track experiment results\n",
    "cols =  ['database', 'chunk_size', 'overlap', 'clean', 'embedding', 'chunks_processed', 'time_to_process', 'used_memory_mb', 'query_time']\n",
    "results = pd.DataFrame(columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries: 500\n"
     ]
    }
   ],
   "source": [
    "with open('example_queries.txt', 'r') as file:\n",
    "\n",
    "    # Skip lines that don't contain actual queries (headers, empty lines) and extract example queries\n",
    "    queries = [line.strip() for line in file if line.strip() and not line.strip().startswith('#') and not line.strip().startswith('##')]\n",
    "    queries = [q.split('. ', 1)[1] if '. ' in q else q for q in queries]\n",
    "    \n",
    "    # Print total count\n",
    "    print(f\"Total queries: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different chunk/overlap/clean combos for filling redis database\n",
    "embedding_model = 'nomic-embed-text'\n",
    "db = 'redis'\n",
    "\n",
    "# loop through different options\n",
    "for chunk in [100,300,500,1000]:\n",
    "    for overlap in [0, 50, 100]:\n",
    "\n",
    "        if overlap >= chunk:\n",
    "            continue\n",
    "        for clean in [True, False]:\n",
    "\n",
    "            # clear store before starting\n",
    "            clear_redis_store()\n",
    "\n",
    "            # create and fill redis store\n",
    "            start = time.time()\n",
    "            create_hnsw_index()\n",
    "            chunk_count = process_pdfs_redis(\"data/\", chunk_size=chunk, overlap=overlap, clean = clean)\n",
    "            to_fill = time.time() - start\n",
    "            print(f'Index with chunk size {chunk} and overlap {overlap} created in {round(to_fill, 2)} seconds')\n",
    "\n",
    "\n",
    "            # Get memory usage info\n",
    "            memory_info = redis_client.info('memory')\n",
    "            used_memory = memory_info['used_memory'] \n",
    "            used_memory_mb = used_memory / (1024 * 1024)\n",
    "\n",
    "            # test retrieval speed\n",
    "            start = time.time()\n",
    "            for query in queries:\n",
    "                query_redis(query)\n",
    "            to_search = time.time()- start\n",
    "            print(f'Search with chunk size {chunk} and overlap {overlap} completed in {round(to_search, 2)} seconds')\n",
    "\n",
    "            # add results to result dataframe\n",
    "            new_row = [db, chunk, overlap, clean, embedding_model, chunk_count, to_fill, used_memory_mb, to_search]\n",
    "            results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear store before starting\n",
    "clear_redis_store()\n",
    "\n",
    "# create and fill redis store\n",
    "start = time.time()\n",
    "create_hnsw_index()\n",
    "chunk_count = process_pdfs_redis(\"data/\", chunk_size=500, overlap=100, clean = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with chunk size 100 and overlap 0 created in 18.19 seconds\n",
      "It uses 1274880 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 10.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/c154mt9s11x5q965j91l06qw0000gn/T/ipykernel_63061/1874157469.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with chunk size 100 and overlap 0 created in 24.29 seconds\n",
      "It uses 1299456 MB\n",
      "Search with chunk size 100 and overlap 0 completed in 10.88 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 30.07 seconds\n",
      "It uses 1956864 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 10.88 seconds\n",
      "Index with chunk size 100 and overlap 50 created in 30.17 seconds\n",
      "It uses 2055168 MB\n",
      "Search with chunk size 100 and overlap 50 completed in 11.04 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 19.06 seconds\n",
      "It uses 930816 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 10.91 seconds\n",
      "Index with chunk size 300 and overlap 0 created in 19.89 seconds\n",
      "It uses 936960 MB\n",
      "Search with chunk size 300 and overlap 0 completed in 9.19 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m start = time.time()\n\u001b[32m     15\u001b[39m collection = create_chroma_index(embedding_model)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m collection, chunk_count = \u001b[43mprocess_pdfs_chroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m to_fill = time.time() - start\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIndex with chunk size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and overlap \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverlap\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m created in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(to_fill,\u001b[38;5;250m \u001b[39m\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/DS_4300/DS4300-RAG-Practical/src/ingest_chroma.py:57\u001b[39m, in \u001b[36mprocess_pdfs_chroma\u001b[39m\u001b[34m(collection, data_dir, chunk_size, overlap, clean)\u001b[39m\n\u001b[32m     54\u001b[39m             ids = [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(chunk_count, chunk_count+\u001b[38;5;28mlen\u001b[39m(chunks)))]\n\u001b[32m     55\u001b[39m             chunk_count += \u001b[38;5;28mlen\u001b[39m(chunks)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m             \u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection, chunk_count\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/chromadb/api/models/Collection.py:82\u001b[39m, in \u001b[36mCollection.add\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     49\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     60\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     61\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \n\u001b[32m     80\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     add_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._add(\n\u001b[32m     92\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m     93\u001b[39m         ids=add_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    100\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:90\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     92\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:213\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_add_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    212\u001b[39m     validate_record_set_for_embedding(record_set=add_records)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     add_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     add_embeddings = add_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:526\u001b[39m, in \u001b[36mCollectionCommon._embed_record_set\u001b[39m\u001b[34m(self, record_set, embeddable_fields)\u001b[39m\n\u001b[32m    522\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed(\n\u001b[32m    523\u001b[39m                 \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28mself\u001b[39m._data_loader(uris=cast(URIs, record_set[field]))  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    524\u001b[39m             )\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    528\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    530\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/chromadb/api/models/CollectionCommon.py:539\u001b[39m, in \u001b[36mCollectionCommon._embed\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    536\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.trychroma.com/guides/embeddings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/chromadb/api/types.py:466\u001b[39m, in \u001b[36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) -> Embeddings:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(cast(Embeddings, normalize_embeddings(result)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/DS_4300/DS4300-RAG-Practical/src/ingest_chroma.py:21\u001b[39m, in \u001b[36mChromaEmbedding.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/DS_4300/DS4300-RAG-Practical/src/ingest_redis.py:49\u001b[39m, in \u001b[36mget_embedding\u001b[39m\u001b[34m(text, model)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mnomic-embed-text\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     response = \u001b[43mollama\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/ollama/_client.py:380\u001b[39m, in \u001b[36mClient.embeddings\u001b[39m\u001b[34m(self, model, prompt, options, keep_alive)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membeddings\u001b[39m(\n\u001b[32m    371\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    372\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    375\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    376\u001b[39m ) -> EmbeddingsResponse:\n\u001b[32m    377\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m  Deprecated in favor of `embed`.\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbeddingsResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/embeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmbeddingsRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/ollama/_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/ollama/_client.py:118\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    117\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     r.raise_for_status()\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpx/_client.py:827\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    812\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[32m    814\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    815\u001b[39m     method=method,\n\u001b[32m    816\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    825\u001b[39m     extensions=extensions,\n\u001b[32m    826\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    906\u001b[39m follow_redirects = (\n\u001b[32m    907\u001b[39m     \u001b[38;5;28mself\u001b[39m.follow_redirects\n\u001b[32m    908\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[32m    909\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[32m    910\u001b[39m )\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpx/_client.py:1015\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1010\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1011\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1012\u001b[39m     )\n\u001b[32m   1014\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1015\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1019\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpx/_transports/default.py:233\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    220\u001b[39m req = httpcore.Request(\n\u001b[32m    221\u001b[39m     method=request.method,\n\u001b[32m    222\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m     extensions=request.extensions,\n\u001b[32m    231\u001b[39m )\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    238\u001b[39m     status_code=resp.status,\n\u001b[32m    239\u001b[39m     headers=resp.headers,\n\u001b[32m    240\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    241\u001b[39m     extensions=resp.extensions,\n\u001b[32m    242\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:268\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    267\u001b[39m         \u001b[38;5;28mself\u001b[39m.response_closed(status)\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:251\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    253\u001b[39m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool_lock:\n\u001b[32m    261\u001b[39m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[32m    262\u001b[39m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.is_available():\n\u001b[32m    101\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpcore/_sync/http11.py:133\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    132\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpcore/_sync/http11.py:111\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m    104\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m    105\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    106\u001b[39m     (\n\u001b[32m    107\u001b[39m         http_version,\n\u001b[32m    108\u001b[39m         status,\n\u001b[32m    109\u001b[39m         reason_phrase,\n\u001b[32m    110\u001b[39m         headers,\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     trace.return_value = (\n\u001b[32m    113\u001b[39m         http_version,\n\u001b[32m    114\u001b[39m         status,\n\u001b[32m    115\u001b[39m         reason_phrase,\n\u001b[32m    116\u001b[39m         headers,\n\u001b[32m    117\u001b[39m     )\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    120\u001b[39m     status=status,\n\u001b[32m    121\u001b[39m     headers=headers,\n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m     },\n\u001b[32m    128\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpcore/_sync/http11.py:176\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    173\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpcore/_sync/http11.py:212\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    209\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/httpcore/_backends/sync.py:126\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    125\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# test different chunk/overlap/clean combos for filling redis database\n",
    "embedding_model = 'mxbai-embed-large'\n",
    "embedding_size = 768\n",
    "db = 'chroma'\n",
    "\n",
    "# loop through different options\n",
    "for chunk in [100,300,500,1000]:\n",
    "    for overlap in [0, 50, 100]:\n",
    "        if overlap >= chunk:\n",
    "            continue\n",
    "        for clean in [True, False]:\n",
    "\n",
    "            # create and fill redis store\n",
    "            start = time.time()\n",
    "            collection = create_chroma_index(embedding_model)\n",
    "            collection, chunk_count = process_pdfs_chroma(collection, \"data/\", chunk_size=chunk, overlap=overlap, clean = clean)\n",
    "            to_fill = time.time() - start\n",
    "            print(f'Index with chunk size {chunk} and overlap {overlap} created in {round(to_fill, 2)} seconds')\n",
    "\n",
    "            num_vectors = len(collection.get()[\"ids\"])  # Number of stored items\n",
    "            embedding_size = 768  # Adjust based on your embedding model\n",
    "            float_size = np.dtype(np.float32).itemsize  # 4 bytes per float\n",
    "\n",
    "            memory_usage_bytes = num_vectors * embedding_size * float_size\n",
    "            memory_usage_mb = memory_usage_bytes / (1024 * 1024)\n",
    "            print(f\"It uses {memory_usage_bytes} MB\")\n",
    "\n",
    "            # test searching speed\n",
    "            start = time.time()\n",
    "            query_chroma(collection, queries)\n",
    "            to_search = time.time()-start\n",
    "            print(f'Search with chunk size {chunk} and overlap {overlap} completed in {round(to_search, 2)} seconds')\n",
    "\n",
    "            # add results to result dataframe\n",
    "            new_row = [db, chunk, overlap, clean, embedding_model, chunk_count, to_fill, memory_usage_mb, to_search]\n",
    "            results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection with chunk size 100 and overlap 0 created in 10.15 seconds\n",
      "It uses 1274880 MB\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for EmbeddingsRequest\nprompt\n  Input should be a valid string [type=string_type, input_value=['What is a relational da... parallelization work?'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# test searching speed\u001b[39;00m\n\u001b[32m     29\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mquery_milvus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m to_search = time.time()-start\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSearch with chunk size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and overlap \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverlap\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(to_search,\u001b[38;5;250m \u001b[39m\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/DS_4300/DS4300-RAG-Practical/src/ingest_milvus.py:56\u001b[39m, in \u001b[36mquery_milvus\u001b[39m\u001b[34m(collection, query_text, top_k)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery_milvus\u001b[39m(collection, query_text, top_k=\u001b[32m5\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     embedding = \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     search_params = {\u001b[33m\"\u001b[39m\u001b[33mmetric_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCOSINE\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mef\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m100\u001b[39m}}\n\u001b[32m     58\u001b[39m     results = collection.search([embedding], \u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m, search_params, top_k=top_k, output_fields=[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/DS_4300/DS4300-RAG-Practical/src/ingest_redis.py:49\u001b[39m, in \u001b[36mget_embedding\u001b[39m\u001b[34m(text, model)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mnomic-embed-text\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     response = \u001b[43mollama\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/ollama/_client.py:384\u001b[39m, in \u001b[36mClient.embeddings\u001b[39m\u001b[34m(self, model, prompt, options, keep_alive)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membeddings\u001b[39m(\n\u001b[32m    371\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    372\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    375\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    376\u001b[39m ) -> EmbeddingsResponse:\n\u001b[32m    377\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m  Deprecated in favor of `embed`.\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m    380\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m    381\u001b[39m     EmbeddingsResponse,\n\u001b[32m    382\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    383\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m/api/embeddings\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     json=\u001b[43mEmbeddingsRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.model_dump(exclude_none=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    390\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/prac_2_env/lib/python3.13/site-packages/pydantic/main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for EmbeddingsRequest\nprompt\n  Input should be a valid string [type=string_type, input_value=['What is a relational da... parallelization work?'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type"
     ]
    }
   ],
   "source": [
    "# test different chunk/overlap/clean combos for filling redis database\n",
    "embedding_model = 'nomic-embed-text'\n",
    "embedding_size = 768\n",
    "db = 'milvus'\n",
    "\n",
    "# loop through different options\n",
    "for chunk in [100,300,500,1000]:\n",
    "    for overlap in [0, 50, 100]:\n",
    "        if overlap >= chunk:\n",
    "            continue\n",
    "        for clean in [True, False]:\n",
    "\n",
    "            # create and fill redis store\n",
    "            start = time.time()\n",
    "            collection = create_milvus_collection(embed_model = embedding_model)\n",
    "            collection, chunk_count = process_pdfs_milvus(collection, \"data/\", chunk_size=chunk, overlap=overlap, clean = clean)\n",
    "            to_fill = time.time() - start\n",
    "            print(f'Collection with chunk size {chunk} and overlap {overlap} created in {round(to_fill, 2)} seconds')\n",
    "\n",
    "            # get number\n",
    "            num_vectors = collection.num_entities \n",
    "            embedding_size = 768  \n",
    "            float_size = np.dtype(np.float32).itemsize  \n",
    "\n",
    "            memory_usage_bytes = num_vectors * embedding_size * float_size\n",
    "            memory_usage_mb = memory_usage_bytes / (1024 * 1024)\n",
    "            print(f\"It uses {memory_usage_bytes} MB\")\n",
    "\n",
    "            # test searching speed\n",
    "            start = time.time()\n",
    "            query_milvus(collection, queries)\n",
    "            to_search = time.time()-start\n",
    "            print(f'Search with chunk size {chunk} and overlap {overlap} completed in {round(to_search, 2)} seconds')\n",
    "\n",
    "            # add results to result dataframe\n",
    "            new_row = [db, chunk, overlap, clean, embedding_model, chunk_count, to_fill, used_memory_mb, to_search]\n",
    "            results = pd.concat([results, pd.DataFrame([new_row], columns=cols)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = 'mxbai-embed-large:latest'\n",
    "\n",
    "collection = create_chroma_index(embedding_model)\n",
    "collection, chunk_count = process_pdfs_chroma(collection, \"data/\", chunk_size=500, overlap=100, clean = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RAG Search Interface\n",
      "Type 'exit' to quit\n",
      "[['193', '186', '187', '118', '116', '295', '117', '114', '253', '204']]\n",
      "{'ids': [['193', '186', '187', '118', '116', '295', '117', '114', '253', '204']], 'distances': [[240.52713, 265.7791, 268.0335, 268.64575, 269.59592, 273.60944, 283.7926, 286.72388, 294.18234, 294.6806]], 'embeddings': None, 'metadatas': [[None, None, None, None, None, None, None, None, None, None]], 'documents': [['ACID Properties Durability Once a transaction is completed and committed successfully its changes are permanent Even in the event of a system failure committed transactions are preserved For more info on Transactions see Kleppmann Book Chapter 7 12', 'ACID Properties Atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed Consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints 5', 'ACID Properties Isolation Two transactions T1 and T2 are being executed at the same time but cannot affect each other If both T1 and T2 are reading the data no problem If T1 is reading the same data that T2 may be writing can result in Dirty Read Nonrepeatable Read Phantom Reads 6', 'ACID Alternative for Distrib Systems BASE Eventual Consistency The system will eventually become consistent All writes will eventually stop so all nodesreplicas can be updated 10', 'ACID Alternative for Distrib Systems BASE Basically Available Guarantees the availability of the data per CAP but response can be failureunreliable because the data is in an inconsistent or changing state System appears to work most of the time 8', '7', 'ACID Alternative for Distrib Systems BASE Soft State The state of the system could change over time even wo input Changes could be result of eventual consistency Data stores dont have to be writeconsistent Replicas dont have to be mutually consistent 9', 'CAP Theorem Review 6 Reference httpsalperenbayramoglucompostsunderstandingcaptheorem You can have 2 but not 3 of the following Consistency Every user of the DB has an identical view of the data at any given instant Availability In the event of a failure the database system remains operational Partition Tolerance The database can maintain operations in the event of the networks failing between two segments of the distributed system Note the definition of Consistency in CAP is different from that of ACID', '37', '23']], 'uris': None, 'data': None, 'included': [<IncludeEnum.metadatas: 'metadatas'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.distances: 'distances'>]}\n",
      "context_str: From Unknown file (page Unknown page, chunk ACID Properties Durability Once a transaction is completed and committed successfully its changes are permanent Even in the event of a system failure committed transactions are preserved For more info on Transactions see Kleppmann Book Chapter 7 12) with similarity 240.53\n",
      "From Unknown file (page Unknown page, chunk ACID Properties Atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed Consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints 5) with similarity 265.78\n",
      "From Unknown file (page Unknown page, chunk ACID Properties Isolation Two transactions T1 and T2 are being executed at the same time but cannot affect each other If both T1 and T2 are reading the data no problem If T1 is reading the same data that T2 may be writing can result in Dirty Read Nonrepeatable Read Phantom Reads 6) with similarity 268.03\n",
      "From Unknown file (page Unknown page, chunk ACID Alternative for Distrib Systems BASE Eventual Consistency The system will eventually become consistent All writes will eventually stop so all nodesreplicas can be updated 10) with similarity 268.65\n",
      "From Unknown file (page Unknown page, chunk ACID Alternative for Distrib Systems BASE Basically Available Guarantees the availability of the data per CAP but response can be failureunreliable because the data is in an inconsistent or changing state System appears to work most of the time 8) with similarity 269.60\n",
      "From Unknown file (page Unknown page, chunk 7) with similarity 273.61\n",
      "From Unknown file (page Unknown page, chunk ACID Alternative for Distrib Systems BASE Soft State The state of the system could change over time even wo input Changes could be result of eventual consistency Data stores dont have to be writeconsistent Replicas dont have to be mutually consistent 9) with similarity 283.79\n",
      "From Unknown file (page Unknown page, chunk CAP Theorem Review 6 Reference httpsalperenbayramoglucompostsunderstandingcaptheorem You can have 2 but not 3 of the following Consistency Every user of the DB has an identical view of the data at any given instant Availability In the event of a failure the database system remains operational Partition Tolerance The database can maintain operations in the event of the networks failing between two segments of the distributed system Note the definition of Consistency in CAP is different from that of ACID) with similarity 286.72\n",
      "From Unknown file (page Unknown page, chunk 37) with similarity 294.18\n",
      "From Unknown file (page Unknown page, chunk 23) with similarity 294.68\n",
      "\n",
      "--- Response ---\n",
      " The parts of ACID compliance are Atomicity, Consistency, Isolation, and Durability. These properties ensure that database transactions are processed reliably in a way that guarantees their integrity and consistency across all operations.\n",
      "[['277', '256', '255', '257', '252', '251', '254', '278', '258', '259']]\n",
      "{'ids': [['277', '256', '255', '257', '252', '251', '254', '278', '258', '259']], 'distances': [[94.77336, 119.34935, 131.87325, 147.3265, 151.51596, 156.48149, 166.64474, 189.17993, 208.69693, 213.16272]], 'embeddings': None, 'metadatas': [[None, None, None, None, None, None, None, None, None, None]], 'documents': [['\\u200b choose that either always go left always go right or are ignored \\u200b Want to minimize height of Tree make more balanced \\u200b need AVL tree for this AVL Tree \\u200b approx balanced binary search tree \\u200b each node has a balance factor \\u200b hLST HRST1 \\u200b height of left sub tree and rightsubtree should have one or 0 level difference \\u200b Check for imbalance in every node in path to root \\u200b If one node is imbalance the new node takes spot of imbalance node and it is rebuilt from there \\u200b simplification \\u200b 4 cases of imbalance 1\\u200b LL left left case a\\u200b use a single rotation b\\u200b Pseudocode cleft aright aright c 2\\u200b LR left right case a\\u200b use a double rotation b\\u200b Pseudo code cleft ba aright bleft bleft a bright c', 'is If the first link is to the right and the second is to the left perform an RL rotation rooted where the imbalance is It can be shown that any one of these rotations  LL RR LR or RL  will correct any imbalance brought on by inserting a key In this case wed perform an LR rotation  the first two links leading from 40 down toward 35 are a Left and a Right  rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this Compare this to the diagram describing an LR rotation The node containing 40 is C The node containing 30 is A The node containing 35 is B The empty left subtree of the node containing 30 is T1 The empty left subtree of the node containing 35 is T2 The empty right subtree of the node containing 35 is T3 The empty right subtree of the node containing 40 is T4 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 57', 'Inserting a key into an AVL tree starts out the same way as insertion into a binary search tree Perform a lookup If you find the key already in the tree youre done because keys in a binary search tree must be unique When the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended The problem is that adding the new node introduced the possibility of an imbalance For example suppose we started with this AVL tree and then we inserted the key 35 into it A binary search tree insertion would give us this as a result But this resulting tree is not an AVL tree because the node containing the key 40 does not have the AVL property because the difference in the heights of its subtrees is 2 Its left subtree has height 1 its right subtree  which is empty  has height 1 What can we do about it The answer lies in the following algorithm which we perform after the normal insertion process Work your way back up the tree from the position where you just added a node This could be quite simple if the insertion was done recursively Compare the heights of the left and right subtrees of each node When they differ by more than 1 choose a rotation that will fix the imbalance Note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were The solution to this problem is for each node to store its height ie the height of the subtree rooted there This can be cheaply updated after every insertion or removal as you unwind the recursion The rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node If you were wondering where the names LL RR LR and RL come from this is the answer to that mystery If the two links are both to the left perform an LL rotation rooted where the imbalance is If the two links are both to the right perform an RR rotation rooted where the imbalance is If the first link is to the left and the second is to the right perform an LR rotation rooted where the imbalance is If the first link is to the right and the second is to the left perform an RL rotation rooted where the imbalance is It can be shown that any one of these rotations  LL RR LR or RL  will correct any imbalance brought on by inserting a key In this case wed perform an LR rotation  the first two links leading from 40 down toward 35 are a Left and a Right  rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this Compare this to the', 'After the rotation we see what wed expect The node B which in our example contained 35 is now the root of the newlyrotated subtree The node A which in our example contained 30 is now the left child of the root of the newlyrotated subtree The node C which in our example contained 40 is now the right child of the root of the newlyrotated subtree The four subtrees T1 T2 T3 and T4 were all empty so they are still empty Note too that the tree is more balanced after the rotation than it was before This is no accident a single rotation LL RR LR or RL is all thats necessary to correct an imbalance introduced by the insertion algorithm A removal algorithm Removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds The key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred  so generally Olog n rotations Asymptotic analysis The key question here is What is the height of an AVL tree with n nodes If the answer is log n then we can be certain that lookups insertions and removals will take Olog n time How can we be so sure Lookups would be Olog n because theyre the same as they are in a binary search tree that doesnt have the AVL property If the height of the tree is log n lookups will run in Olog n time Insertions and removals despite being slightly more complicated in an AVL tree do their work by traversing a single path in the tree  potentially all the way down to a leaf position then all the way back up If the length of the longest path  thats what the height of a tree is  is log n then we know that none of these paths is longer than that so insertions and removals will take Olog n time So were left with that key question What is the height of an AVL tree with n nodes If youre not curious you can feel free to just assume this if you want to know more keep reading What is the height of an AVL tree with n nodes Optional The answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an AVL tree It turns out AVL trees of height n  2 that have the minimum number of nodes in them all share a similar property The AVL tree with height h  2 with the minimum number of nodes consists of a root node with two subtrees one of which is an AVL tree with height h  1 with the minimum number', 'a root node and empty subtrees would then be zero But what about a tree thats totally empty To maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 This means that a node with say a childless left child and no right child would still be considered balanced This leads us finally to the definition of an AVL tree An AVL tree is a binary search tree in which all nodes have the AVL property Below are a few binary trees two of which are AVL and two of which are not The thing to keep in mind about AVL is that its not a matter of squinting at a tree and deciding whether it looks balanced Theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the AVL property AVL trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the AVL property To meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens To do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right Rotations Rebalancing of AVL trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers There are a few kinds of rotations we should first understand how they work then focus our attention on when to use them The first kind of rotation is called an LL rotation which takes the tree on the left and turns it into the tree on the right The circle with A and B written in them are each a single node containing a single key the triangles with T1 T2 and T3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 37', 'enough balanced for our purposes even if not perfect A good balance condition has two properties The height of a binary search tree meeting the condition is log n It takes Olog n time to rebalance the tree on insertions and removals In other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent rebalancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height The cost wont outweigh the benefit Coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for A compromise AVL trees There are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition One of them is called an AVL tree which well explore here Others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now AVL trees AVL trees are what you might called nearly balanced binary search trees While they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost So what makes a binary search tree nearly balanced enough to be considered an AVL tree The core concept is embodied by something called the AVL property We say that a node in a binary search tree has the AVL property if the heights of its left and right subtrees differ by no more than 1 In other words we tolerate a certain amount of imbalance  heights of subtrees can be slightly different but no more than that  in hopes that we can more efficiently maintain it Since were going to be comparing heights of subtrees theres one piece of background we need to consider Recall that the height of a tree is the length of its longest path By definition the height of a tree with just a root node and empty subtrees would then be zero But what about a tree thats totally empty To maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 This means that a node with say a childless left child and no right child would still be considered balanced This leads us finally to the definition of an AVL tree An AVL tree is a binary search tree in which all nodes have the AVL property Below are a few binary trees two of which are AVL and two of', 'Its important to remember that both of these trees  before and after  are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees T1 T2 and T3 maintain the appropriate positions relative to the keys A and B All keys in T1 are smaller than A All keys in T2 are larger than A and smaller than B All keys in T3 are larger than B Performing this rotation would be a simple matter of adjusting a few pointers  notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in 1 time Bs parent would now point to A where it used to point to B As right child would now be B instead of the root of T2 Bs left child would now be the root of T2 instead of A A second kind of rotation is an RR rotation which makes a similar adjustment Note that an RR rotation is the mirror image of an LL rotation A third kind of rotation is an LR rotation which makes an adjustment thats slightly more complicated An LR rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in 1 time Finally there is an RL rotation which is the mirror image of an LR rotation Once we understand the mechanics of how rotations work were one step closer to understanding AVL trees But these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals An insertion algorithm 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 47', '3\\u200b RL right left case a\\u200b mirror of LL case 1 b\\u200b Pseudocode aright cleft cleft a 4\\u200b RR right right case a\\u200b mirror of LR case 2 b\\u200b Pseudocode \\u200b When building out a BST you start inserting at the root and follow down the tree to the correct position then check if each position going back up is balanced \\u200b check the height of left and right subtrees and check the difference 1 \\u200b store height as part of tree node \\u200b update height when going back up subtree \\u200b insert in order 3214567', 'the height of an AVL tree with n nodes Optional The answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an AVL tree It turns out AVL trees of height n  2 that have the minimum number of nodes in them all share a similar property The AVL tree with height h  2 with the minimum number of nodes consists of a root node with two subtrees one of which is an AVL tree with height h  1 with the minimum number of nodes the other of which is an AVL tree with height h  2 with the minimum number of nodes Given that observation we can write a recurrence that describes the number of nodes at minimum in an AVL tree of height h M0 1 When height is 0 minimum number of nodes is 1 a root node with no children M1 2 When height is 1 minimum number of nodes is 2 a root node with one child and not the other Mh 1 Mh 1 Mh 2 While the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily We know for sure that AVL trees with larger heights have a bigger minimum number of nodes than AVL trees with smaller heights  thats fairly selfexplanatory  which means that we can be sure that 1 Mh  1  Mh  2 Given that we can conclude the following Mh  2Mh 2 We can then use the repeated substitution technique to determine a lower bound for this recurrence Mh  2Mh 2  22Mh 4  4Mh 4  42Mh 6  8Mh 6  2jMh 2j We could prove this by induction on j but well accept it on faith let j h2  2h2Mh h  2h2M0 Mh  2h2 So weve shown that the minimum number of nodes that can be present in an AVL tree of height h is at least 2h2 In reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an AVL tree with n nodes Mh  2h2 log2Mh  h2 2 log2Mh  h Finally we see that for AVL trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree For AVL trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 67', ' 2h2 log2Mh  h2 2 log2Mh  h Finally we see that for AVL trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree For AVL trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 67']], 'uris': None, 'data': None, 'included': [<IncludeEnum.metadatas: 'metadatas'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.distances: 'distances'>]}\n",
      "context_str: From Unknown file (page Unknown page, chunk  choose that either always go left always go right or are ignored  Want to minimize height of Tree make more balanced  need AVL tree for this AVL Tree  approx balanced binary search tree  each node has a balance factor  hLST HRST1  height of left sub tree and rightsubtree should have one or 0 level difference  Check for imbalance in every node in path to root  If one node is imbalance the new node takes spot of imbalance node and it is rebuilt from there  simplification  4 cases of imbalance 1 LL left left case a use a single rotation b Pseudocode cleft aright aright c 2 LR left right case a use a double rotation b Pseudo code cleft ba aright bleft bleft a bright c) with similarity 94.77\n",
      "From Unknown file (page Unknown page, chunk is If the first link is to the right and the second is to the left perform an RL rotation rooted where the imbalance is It can be shown that any one of these rotations  LL RR LR or RL  will correct any imbalance brought on by inserting a key In this case wed perform an LR rotation  the first two links leading from 40 down toward 35 are a Left and a Right  rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this Compare this to the diagram describing an LR rotation The node containing 40 is C The node containing 30 is A The node containing 35 is B The empty left subtree of the node containing 30 is T1 The empty left subtree of the node containing 35 is T2 The empty right subtree of the node containing 35 is T3 The empty right subtree of the node containing 40 is T4 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 57) with similarity 119.35\n",
      "From Unknown file (page Unknown page, chunk Inserting a key into an AVL tree starts out the same way as insertion into a binary search tree Perform a lookup If you find the key already in the tree youre done because keys in a binary search tree must be unique When the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended The problem is that adding the new node introduced the possibility of an imbalance For example suppose we started with this AVL tree and then we inserted the key 35 into it A binary search tree insertion would give us this as a result But this resulting tree is not an AVL tree because the node containing the key 40 does not have the AVL property because the difference in the heights of its subtrees is 2 Its left subtree has height 1 its right subtree  which is empty  has height 1 What can we do about it The answer lies in the following algorithm which we perform after the normal insertion process Work your way back up the tree from the position where you just added a node This could be quite simple if the insertion was done recursively Compare the heights of the left and right subtrees of each node When they differ by more than 1 choose a rotation that will fix the imbalance Note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were The solution to this problem is for each node to store its height ie the height of the subtree rooted there This can be cheaply updated after every insertion or removal as you unwind the recursion The rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node If you were wondering where the names LL RR LR and RL come from this is the answer to that mystery If the two links are both to the left perform an LL rotation rooted where the imbalance is If the two links are both to the right perform an RR rotation rooted where the imbalance is If the first link is to the left and the second is to the right perform an LR rotation rooted where the imbalance is If the first link is to the right and the second is to the left perform an RL rotation rooted where the imbalance is It can be shown that any one of these rotations  LL RR LR or RL  will correct any imbalance brought on by inserting a key In this case wed perform an LR rotation  the first two links leading from 40 down toward 35 are a Left and a Right  rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this Compare this to the) with similarity 131.87\n",
      "From Unknown file (page Unknown page, chunk After the rotation we see what wed expect The node B which in our example contained 35 is now the root of the newlyrotated subtree The node A which in our example contained 30 is now the left child of the root of the newlyrotated subtree The node C which in our example contained 40 is now the right child of the root of the newlyrotated subtree The four subtrees T1 T2 T3 and T4 were all empty so they are still empty Note too that the tree is more balanced after the rotation than it was before This is no accident a single rotation LL RR LR or RL is all thats necessary to correct an imbalance introduced by the insertion algorithm A removal algorithm Removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds The key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred  so generally Olog n rotations Asymptotic analysis The key question here is What is the height of an AVL tree with n nodes If the answer is log n then we can be certain that lookups insertions and removals will take Olog n time How can we be so sure Lookups would be Olog n because theyre the same as they are in a binary search tree that doesnt have the AVL property If the height of the tree is log n lookups will run in Olog n time Insertions and removals despite being slightly more complicated in an AVL tree do their work by traversing a single path in the tree  potentially all the way down to a leaf position then all the way back up If the length of the longest path  thats what the height of a tree is  is log n then we know that none of these paths is longer than that so insertions and removals will take Olog n time So were left with that key question What is the height of an AVL tree with n nodes If youre not curious you can feel free to just assume this if you want to know more keep reading What is the height of an AVL tree with n nodes Optional The answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an AVL tree It turns out AVL trees of height n  2 that have the minimum number of nodes in them all share a similar property The AVL tree with height h  2 with the minimum number of nodes consists of a root node with two subtrees one of which is an AVL tree with height h  1 with the minimum number) with similarity 147.33\n",
      "From Unknown file (page Unknown page, chunk a root node and empty subtrees would then be zero But what about a tree thats totally empty To maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 This means that a node with say a childless left child and no right child would still be considered balanced This leads us finally to the definition of an AVL tree An AVL tree is a binary search tree in which all nodes have the AVL property Below are a few binary trees two of which are AVL and two of which are not The thing to keep in mind about AVL is that its not a matter of squinting at a tree and deciding whether it looks balanced Theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the AVL property AVL trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the AVL property To meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens To do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right Rotations Rebalancing of AVL trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers There are a few kinds of rotations we should first understand how they work then focus our attention on when to use them The first kind of rotation is called an LL rotation which takes the tree on the left and turns it into the tree on the right The circle with A and B written in them are each a single node containing a single key the triangles with T1 T2 and T3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 37) with similarity 151.52\n",
      "From Unknown file (page Unknown page, chunk enough balanced for our purposes even if not perfect A good balance condition has two properties The height of a binary search tree meeting the condition is log n It takes Olog n time to rebalance the tree on insertions and removals In other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent rebalancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height The cost wont outweigh the benefit Coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for A compromise AVL trees There are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition One of them is called an AVL tree which well explore here Others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now AVL trees AVL trees are what you might called nearly balanced binary search trees While they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost So what makes a binary search tree nearly balanced enough to be considered an AVL tree The core concept is embodied by something called the AVL property We say that a node in a binary search tree has the AVL property if the heights of its left and right subtrees differ by no more than 1 In other words we tolerate a certain amount of imbalance  heights of subtrees can be slightly different but no more than that  in hopes that we can more efficiently maintain it Since were going to be comparing heights of subtrees theres one piece of background we need to consider Recall that the height of a tree is the length of its longest path By definition the height of a tree with just a root node and empty subtrees would then be zero But what about a tree thats totally empty To maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 This means that a node with say a childless left child and no right child would still be considered balanced This leads us finally to the definition of an AVL tree An AVL tree is a binary search tree in which all nodes have the AVL property Below are a few binary trees two of which are AVL and two of) with similarity 156.48\n",
      "From Unknown file (page Unknown page, chunk Its important to remember that both of these trees  before and after  are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees T1 T2 and T3 maintain the appropriate positions relative to the keys A and B All keys in T1 are smaller than A All keys in T2 are larger than A and smaller than B All keys in T3 are larger than B Performing this rotation would be a simple matter of adjusting a few pointers  notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in 1 time Bs parent would now point to A where it used to point to B As right child would now be B instead of the root of T2 Bs left child would now be the root of T2 instead of A A second kind of rotation is an RR rotation which makes a similar adjustment Note that an RR rotation is the mirror image of an LL rotation A third kind of rotation is an LR rotation which makes an adjustment thats slightly more complicated An LR rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in 1 time Finally there is an RL rotation which is the mirror image of an LR rotation Once we understand the mechanics of how rotations work were one step closer to understanding AVL trees But these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals An insertion algorithm 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 47) with similarity 166.64\n",
      "From Unknown file (page Unknown page, chunk 3 RL right left case a mirror of LL case 1 b Pseudocode aright cleft cleft a 4 RR right right case a mirror of LR case 2 b Pseudocode  When building out a BST you start inserting at the root and follow down the tree to the correct position then check if each position going back up is balanced  check the height of left and right subtrees and check the difference 1  store height as part of tree node  update height when going back up subtree  insert in order 3214567) with similarity 189.18\n",
      "From Unknown file (page Unknown page, chunk the height of an AVL tree with n nodes Optional The answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an AVL tree It turns out AVL trees of height n  2 that have the minimum number of nodes in them all share a similar property The AVL tree with height h  2 with the minimum number of nodes consists of a root node with two subtrees one of which is an AVL tree with height h  1 with the minimum number of nodes the other of which is an AVL tree with height h  2 with the minimum number of nodes Given that observation we can write a recurrence that describes the number of nodes at minimum in an AVL tree of height h M0 1 When height is 0 minimum number of nodes is 1 a root node with no children M1 2 When height is 1 minimum number of nodes is 2 a root node with one child and not the other Mh 1 Mh 1 Mh 2 While the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily We know for sure that AVL trees with larger heights have a bigger minimum number of nodes than AVL trees with smaller heights  thats fairly selfexplanatory  which means that we can be sure that 1 Mh  1  Mh  2 Given that we can conclude the following Mh  2Mh 2 We can then use the repeated substitution technique to determine a lower bound for this recurrence Mh  2Mh 2  22Mh 4  4Mh 4  42Mh 6  8Mh 6  2jMh 2j We could prove this by induction on j but well accept it on faith let j h2  2h2Mh h  2h2M0 Mh  2h2 So weve shown that the minimum number of nodes that can be present in an AVL tree of height h is at least 2h2 In reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an AVL tree with n nodes Mh  2h2 log2Mh  h2 2 log2Mh  h Finally we see that for AVL trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree For AVL trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 67) with similarity 208.70\n",
      "From Unknown file (page Unknown page, chunk  2h2 log2Mh  h2 2 log2Mh  h Finally we see that for AVL trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree For AVL trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for 31025 1001 AM ICS 46 Spring 2022 Notes and Examples AVL Trees httpsicsucieduthorntonics46NotesAVLTrees 67) with similarity 213.16\n",
      "\n",
      "--- Response ---\n",
      " To deal with right-left imbalance in an AVL tree, you can follow the pseudocode provided for the Right-Left (RL) case in the given text:\n",
      "\n",
      "1. RL right-left case a:\n",
      "   - If the current node is a left child, perform a right rotation followed by a left rotation at the grandparent node.\n",
      "   - If the current node is the root, perform a left rotation followed by a right rotation at the new root (the old root's former left child).\n",
      "\n",
      "2. Pseudocode:\n",
      "\n",
      "```\n",
      "RL case a:\n",
      "  a) Right Rotation (aright, cleft)\n",
      "    - Create a temporary node called temp and set it to cleft.left\n",
      "    - Set cleft.left to aright\n",
      "    - Set aright.parent to temp\n",
      "    - Set temp.right to aright\n",
      "    - If temp has a parent:\n",
      "      - If the parent is the root, update the root to temp\n",
      "      - Otherwise, if the parent is the left child of its parent:\n",
      "        - Update the parent's left child to temp\n",
      "  b) Left Rotation (cleft, cleft_left)\n",
      "    - Set cleft.parent as the new parent for cleft_left\n",
      "    - Set cleft_left.parent as the old parent of cleft\n",
      "```\n",
      "\n",
      "This pseudocode demonstrates how to correct a right-left imbalance in an AVL tree by performing rotations on nodes as needed.\n"
     ]
    }
   ],
   "source": [
    "interactive_search(\"chroma\", embed_model=\"mxbai-embed-large:latest\", llm=\"mistral:latest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS4300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
